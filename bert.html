<!doctype html>
<html lang="en" class="">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="description" content="Pretained Image Recognition Models">
    <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.9">
    <title>DeepAR</title>

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css">
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href=""
        href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
    <link rel="stylesheet" href="css/style.css">
    <!-- <script>__md_scope=new URL(".",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script> -->

</head>

<body>
    <header class="">
        <nav class="navbar navbar-expand-lg navbar-light bg txt-white fixed-top">
            <div class="container-fluid container">
                <div class="">
                    <label><i class="ri-bar-chart-grouped-line"></i></label>
                    <a class="navbar-brand txt-white" href="#">Int Elligence</a>
                </div>

                <div class="d-flex ">
                    <a class="navbar-brand txt-white" href="https://github.com/IntElligence0">Packages</a>
                </div>
            </div>
        </nav>

    </header>

    <section class="sec-margin-top">
        <div>
            <div class="container-fluid">
                <div class="row">

                    <div class="col-lg-3 col-md-3 col-sm-3">
                        <div class="margin-top">
                            <h5>Tensorflow Forcasting Models</h5>
                            <div id="myDIV">
                                <div class=" flex activation margin-top active" style="width: 35%;">
                                    <a class="activation" href="index.html"><i class="ri-home-gear-fill"></i>

                                        <p style="margin-top: -26px; margin-left: 18px;">Getting start</p>
                                    </a>
                                </div>

                                <div class=" flex activation active" style="width: 42%;">
                                    <a class="activation" href="model summary.html"><i class="ri-file-list-3-fill"></i>
                                        <p style="margin-top: -26px; margin-left: 18px;">Model summarize</p>
                                    </a>
                                </div>
                                <div class="dropdown" style="width: 416px;">
                                    <a class="dropdown-toggle" href="#" id="dropdownMenuLink" data-bs-toggle="dropdown"
                                        aria-expanded="false"><i class="ri-article-fill"></i>
                                        Model Pages
                                    </a>

                                    <ul class="dropdown-menu" aria-labelledby="dropdownMenuLink"
                                        style="overflow: scroll; height: 357px;">
                                        <li><a class="dropdown-item activation hov" href="TCN.html">Temporal
                                                Convolutional
                                                Networks
                                                TCN</a>
                                        </li>
                                        <li><a class="dropdown-item activation hov"
                                                href="transformer.html">Transformer</a></li>
                                        <li><a class="dropdown-item activation hov" href="performer.html">Performer</a>
                                        </li>
                                        <li><a class="dropdown-item activation hov" href="CNN-LSTM.html">CNN Long
                                                Short-Term Memory
                                                Networks (CNN-LSTM)</a></li>
                                        <li><a class="dropdown-item activation hov" href="Time distributed.html">Time
                                                Distributed</a></li>
                                        <li><a class="dropdown-item activation hov" href="Bi-lstm.html">Bi-directional
                                                long short
                                                term memory (Bi-LSTM)</a></li>
                                        <li><a class="dropdown-item activation hov" href="BiGru.html">Bi-directional
                                                Gated
                                                Recurrent Units (Bi-GRU)</a></li>
                                        <li><a class="dropdown-item activation hov" href="gru.html">Gated Recurrent
                                                Units
                                                (GRU)</a></li>
                                        <li><a class="dropdown-item activation hov" href="cnn.html">Convolutional Neural
                                                Network (CNN)</a></li>
                                        <li><a class="dropdown-item activation hov" href="lstm.html">Long Short-Term
                                                Memory
                                                networks (LSTM)</a></li>
                                        <li><a class="dropdown-item activation hov" href="deepar.html">DeepAR</a></li>
                                        <li><a class="dropdown-item activation hov" href="tlnn.html">Time Lagged
                                                Neural
                                                Network (TLNN)</a></li>
                                        <li><a class="dropdown-item activation hov" href="bert.html">Bidirectional
                                                Encoder Representations from Transformers
                                                (Bert)</a></li>
                                        <li><a class="dropdown-item activation hov" href="Seq2seq.html">Seq2Seq
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="fnn.html">feedforward neural
                                                network (FNN)
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="N-BEATS.html">N-BEATS
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="Autoformer.html">Autoformer
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="rbfn.html">Radial basis
                                                function network (RBFN)
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="mlp.html">mlp
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="convlstm.html">convlstm
                                            </a></li>
                                        <li><a class="dropdown-item activation hov" href="informer.html">Informer
                                            </a></li>
                                    </ul>
                                </div>
                                <div>
                                    <div class=" flex activation margin-top active" style="width: 35%;">
                                        <a class="activation" href="result.html"><i class="ri-question-answer-fill"></i>

                                            <p style="margin-top: -26px; margin-left: 18px;">Results</p>
                                        </a>
                                    </div>
                                    <div class=" flex activation  active" style="width: 42%;">
                                        <a class="activation" href="index.html"><i class="ri-file-edit-fill"></i>

                                            <p style="margin-top: -26px; margin-left: 18px;">Recent changes</p>
                                        </a>
                                    </div>

                                </div>
                            </div>


                        </div>

                    </div>
                    <div class="col-lg-9 col-md-12 col-sm-9 body">

                        <main>
                            <h1 class="">Basic Bidirectional Encoder Representations from Transformers Overview
                                <p>
                                    BERT (Bidirectional Encoder Representations from Transformers) is a recent paper
                                    published by researchers at Google AI
                                    Language. It has caused a stir in the Machine Learning community by presenting
                                    state-of-the-art results in a wide
                                    variety of NLP tasks, including Question Answering (SQuAD v1.1), Natural Language
                                    Inference (MNLI), and others.
                                </p>
                                <p>
                                    BERT’s key technical innovation is applying the bidirectional training of
                                    Transformer, a popular attention model, to
                                    language modelling. This is in contrast to previous efforts which looked at a text
                                    sequence either from left to right or
                                    combined left-to-right and right-to-left training. The paper’s results show that a
                                    language model which is
                                    bidirectionally trained can have a deeper sense of language context and flow than
                                    single-direction language models. In
                                    the paper, the researchers detail a novel technique named Masked LM (MLM) which
                                    allows bidirectional training in models
                                    in which it was previously impossible.
                                </p>


                                <h2>Background</h2>
                                <p>In the field of computer vision, researchers have repeatedly shown the value of
                                    transfer learning — pre-training a
                                    neural network model on a known task, for instance ImageNet, and then performing
                                    fine-tuning — using the trained neural
                                    network as the basis of a new purpose-specific model. In recent years, researchers
                                    have been showing that a similar
                                    technique can be useful in many natural language tasks.
                                </p>

                                <p>A different approach, which is also popular in NLP tasks and exemplified in the
                                    recent ELMo paper, is feature-based
                                    training. In this approach, a pre-trained neural network produces word embeddings
                                    which are then used as features in NLP
                                    models.</p>


                                <h2>How BERT works</h2>
                                <p>BERT makes use of Transformer, an attention mechanism that learns contextual
                                    relations between words (or sub-words) in a
                                    text. In its vanilla form, Transformer includes two separate mechanisms — an encoder
                                    that reads the text input and a
                                    decoder that produces a prediction for the task. Since BERT’s goal is to generate a
                                    language model, only the encoder
                                    mechanism is necessary</p>

                                <p>As opposed to directional models, which read the text input sequentially
                                    (left-to-right or right-to-left), the
                                    Transformer encoder reads the entire sequence of words at once. Therefore it is
                                    considered bidirectional, though it
                                    would be more accurate to say that it’s non-directional. This characteristic allows
                                    the model to learn the context of a
                                    word based on all of its surroundings (left and right of the word).</p>

                                <p>The chart below is a high-level description of the Transformer encoder. The input is
                                    a sequence of tokens, which are
                                    first embedded into vectors and then processed in the neural network. The output is
                                    a sequence of vectors of size H, in
                                    which each vector corresponds to an input token with the same index.</p>

                                <p>When training language models, there is a challenge of defining a prediction goal.
                                    Many models predict the next word in
                                    a sequence (e.g. “The child came home from ___”), a directional approach which
                                    inherently limits context learning. To
                                    overcome this challenge, BERT uses two training strategies:</p>


                                <h2>Masked LM (MLM)</h2>
                                <p>Before feeding word sequences into BERT, 15% of the words in each sequence are
                                    replaced with a [MASK] token. The model
                                    then attempts to predict the original value of the masked words, based on the
                                    context provided by the other, non-masked,
                                    words in the sequence. In technical terms, the prediction of the output words
                                    requires:</p>

                                <p>1.Adding a classification layer on top of the encoder output.</p>
                                <p>2.Multiplying the output vectors by the embedding matrix, transforming them into the
                                    vocabulary dimension.</p>
                                <p>3.Calculating the probability of each word in the vocabulary with softmax.</p>

                                <div class=" bg-size">
                                    <img src="img/0_ViwaI3Vvbnd-CJSQ.webp">
                                </div>

                                <p>The BERT loss function takes into consideration only the prediction of the masked
                                    values and ignores the prediction of
                                    the non-masked words. As a consequence, the model converges slower than directional
                                    models,</p>



                                <div>
                                    <h2>build TLNN model</h2>
                                    <p>now we will know how to use TLNN </p>
                                    <h3>import package</h3>
                                    <div class="" id="Install">
                                        <code class="flex" style="width:100%;">
                                        <p class="line "  id="myText" style="padding-left: 5px;">from <span class="import-color">Energy_Models</span> import 
                                        <span class="import-color">Bert</span> as <span class="import-color">m</span>
                                        </p>
                                        <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                    </code>
                                    </div>
                                    <div>
                                        <h3>call the model</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;">model = m.<span class="import-color">Bert(<span class="package-color">n_steps,n_features,n_outputs</span>)</span>.getModel()
                                            </p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                        <h4>model's parameter</h4>
                                        <p><span class="package-color">n_steps</span> : number of days you want to
                                            predict
                                            on
                                        </p>
                                        <p><span class="package-color">n_features</span> : number of columns in data
                                            that
                                            will
                                            give to model</p>
                                        <p><span class="package-color">n_outputs</span> : number of coulmns that model
                                            will
                                            predict and by default its equal 1</p>
                                    </div>
                                    <div>
                                        <h3>compile the model</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line " id="myText" style="padding-left: 5px;">model.compile(<span class="import-color">optimizer='adam', loss
                                                    ='mse'</span>)
                                            </p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                        <h4>compile parameter </h4>
                                        <p><span class="package-color">optimizer : </span> While training the deep
                                            learning
                                            model, we need to modify each epoch’s weights and minimize the loss
                                            function. An
                                            optimizer is a function or an algorithm that modifies the attributes of the
                                            neural network, such as weights and learning
                                            rate. Thus, it helps in reducing the overall loss and improve the accuracy.
                                            <span class="mid_grey">here we use adam</span>
                                        </p>
                                        <p><span class="package-color">loss : </span>the Loss function is a method of
                                            evaluating how well your algorithm is modeling your dataset</p>
                                    </div>
                                    <div>
                                        <h3>fit the model</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;">history = model.fit(<span class="import-color">X_train, y_train, batch_size=256, validation_split=0.3,epochs=85, verbose=1,
                                            shuffle=False)</span>
                                            </p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                        <h4>fit's parameter</h4>
                                        <p>frist you pass your data then </p>
                                        <p><span class="package-color">batch_size : </span>refers to the number of
                                            training
                                            examples utilized in one iteration</p>
                                        <p><span class="package-color">validation_split : </span>Float between 0 and 1.
                                            Fraction of the training data to be used as validation data; selected from
                                            the
                                            last samples in the x and y data provided, before shuffling.</p>
                                        <p><span class="package-color">epochs : </span>The number of epochs is a
                                            hyperparameter
                                            that defines the number times that the learning algorithm will work through
                                            the
                                            entire training dataset.</p>
                                        <p><span class="package-color">verbose : </span>By setting verbose 0, 1 or 2 you
                                            just
                                            say how do you want to 'see' the training progress for each epoch.</p>

                                    </div>
                                    <div>
                                        <h3>Evaluation_Metrix</h3>
                                        <h3>import package</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                        <p class="line "  id="myText" style="padding-left: 5px;">from <span class="import-color">Energy_Models</span> import 
                                        <span class="import-color">Evaluation_Metrix</span> as <span>mx</span>
                                        </p>
                                        <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                    </code>
                                        </div>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;">mx.print_metrics(<span class="import-color">y_train,y_pred_train,y_test
                                                ,y_pred_test</span>
                                                =m.predict((<span class="import-color">X_train</span>
                                            )</p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                    </div>
                                    <div>


                                        <h3>predict the moodel for testing</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;"><span class="import-color">y_pred_test</span>
                                                =m.predict((<span class="import-color">X_test</span>
                                            )</p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                    </div>
                                    <div>


                                        <h3>predict the moodel for training</h3>
                                        <div class="" id="Install">
                                            <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;"><span class="import-color">y_pred_test</span>
                                                =m.predict((<span class="import-color">X_train</span>
                                            )</p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                        </div>
                                    </div>
                                    <h3>build it from scratch</h3>
                                    <div class="" id="Install">
                                        <code class="flex" style="width:100%;">
                                            <p class="line "  id="myText" style="padding-left: 5px;"> <a href="scratch/LSTM.py" class=""><span class="import-color padding">THE SOURCE CODE <i style="float:right;" class="padding ri-code-box-fill"></i></span></a>
                                            </p>
                                            <!-- <button class="icon" onclick="copyContent()"><i class="ri-file-copy-line"></i></button> -->
                                        </code>
                                    </div>
                                </div>
                        </main>
                        <nav id="toc" class="Fixed">
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <footer class="bg text-center text-lg-start txt-white">
        <!-- Copyright -->
        <div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0.2);">
            © 2020 Copyright:
            <a class="txt-white" href="">created by Int Elligence Team</a>
        </div>
        <!-- Copyright -->
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="js/script.js"></script>


</body>